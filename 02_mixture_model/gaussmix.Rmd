---
title: "Stan Practice- Gaussian Mixture Model"
author: "Will Townes"
date: "April 23, 2016"
output: html_document
---

Here I am trying to create a gaussian mixture model in Stan. Stan doesn't support discrete latent variables so we have to use tricks to integrate them out.

```{r}
library(rstan)
#library(reshape2)
library(knitr) #kable function for pretty table display
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
set.seed(39)
```

### Gaussian Mixture Model
This is from the Stan manual. The generative model is:
$$\mu_k\sim\mathcal{N}(0,1)$$
$$P(Z_n=k) = 1/K$$
$$P(Y_n|Z_n=k) = \mathcal{N}(\mu_k,1)$$
We set $K=2$, $\mu_1=0$, $\mu_2=5$ for illustration.

```{r}
# create fake data
N<-100
D<-c(1)
K<-2
z<-rbinom(N,1,1/2)
mu<-c(0,5)
y<-lapply(z,function(x){rnorm(1,mean=mu[x+1],sd=1)})
y<-unlist(y)
hist(y)
a<-2 # prior sample size, larger values=more regularization of cluster assignments
```

We now fit the stan object to the data. Data are found in the calling environment so there is no need to specify explicitly.

```{r}
stanfile<-"gaussmix2.stan"
system.time(gmm1<-stan(file=stanfile,iter=100,chains=2))
print(gmm1)
```
This sometimes gives a bad result since the posterior mean is not a good estimator for mixture models. An alternative is to do MAP estimation. We can recover a Laplace confidence interval (similar to frequentist Wald interval) by taking the inverse of the negative Hessian matrix.

```{r}
system.time(gmm1<-optimizing(stan_model(file=stanfile),hessian=TRUE))
npars<-3*K-1
post_mean<-gmm1$par #point estimates
sterr<-c(rep(NA,K),sqrt(diag(solve(-gmm1$hessian[2:npars,2:npars]))))
res<-data.frame(post_mean=post_mean,lower=post_mean-sterr*1.96,upper=post_mean+sterr*1.96)
knitr::kable(res)
```

Success! Below is the result from variational inference.

```{r}
system.time(gmm2<-vb(stan_model(file=stanfile)))
summary(gmm2)$summary[1:npars,c("mean","2.5%","97.5%")]
```

